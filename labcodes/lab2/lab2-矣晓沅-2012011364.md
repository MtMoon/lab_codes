lab2 实验报告
=======================
计25 矣晓沅 2012011364
-----------------------------------------
# 练习一
*1.*  设计实现过程

整体的思路即标准的first-fit分配算法的思路。在初始化构建空闲块链表时，即按照地址从低到高进行构建。在pmm.c的page_init函数中，对init_memmap函数进行了调用，语句如下：

     init_memmap(pa2page(begin), (end - begin) / PGSIZE); 
     
在这之前，page_init函数已经完成了内存的探测，并把内存的信息存储在一个e820map结构体中。随后遍历可用的内存区域，调用init_memmap函数对该区域按页建立空闲块链表。在init_memmap中打印相关信息，可以看到：

    init memmap debug size: 32324 
    
实际上可用的内存分区只有一个，即init_memmap实际上只被调用了一次，然后建立了一个32324大的空闲分区。考虑到以后实验中可能有更多的内存可用，所以还是针对此做了相应处理。

查看了lab2_result中相应的实现，我的实现与其有一定的区别。lab2_result中，初始化，分配和回收都是按每一个页进行的，即lab2_result中的空闲块链表中添加了所有的page，并在alloc和free时，对所有的page进行相应的管理操作。我的实现是，在空闲块列表中只保存每个空闲块的第一个page。因为分配和使用时，实际上都是按块进行的，每个块的大小，PG_property  等标志位的信息，都是存在块的首个page中，因此空闲块链表中只需要保存每个块的首页，并且分配和释放时，只需要对首页进行相应的操作即可。如果按照lab2_result中的实现，每次分配和释放一个块是，都得对块中的所有page进行遍历增删。只保存首页时，一来可以节省增删的时间，二来在释放与合并时更方便。如果保存的是所有page，在空闲块列表中插入删除块时，就需要注意，要把该块的首page连接到前一个块的最后一个page上，而该块的后一个块需要与该块的最后一个page相连，此过程相应操作也会浪费一些时间。

具体实现上，init_memmap初始化时，依然对每一个page都初始化，但只是把首页base加入空闲块链表。而在alloc时，顺序遍历链表。因为原来各个page在地址上是由低到高连续的，所以按照first-fit的方法，空闲块链表中各个块的首page在地址上也是由低到高。alloc顺序遍历链表，找到大于等于n的块，从链表中删除该page。如果该块大于n，那么p+n就是该块被分割后剩下的碎片块的首page，此时只需要设置该page的相关参数并加入list即可。free的实现相对要稍微复杂一些。先进行相邻空闲块的合并，通过如下语句判断被释放的块是否有相邻的空闲块：

    base + base->property == p //base右边有空闲块
    p + p->property == base //base左边有空闲块
    
合并时，页只需修改相应首page的参数和增删相应首page即可。lab2_result中是统一采用list_add_before来添加，这样就比较简单。我实现是没有考虑到这一点，都采用了list_add(add after), 所以在合并完后，将base加入空闲块链表时，需要注意处理几种情况。一是此时链表为空，则直接加到头指针后；而是链表非空，则遍历链表，找到地址合适的位置进行添加。

*2.* 改进空间

按上述实现，应该比lab2_result要简单一些，但是因为没看lab3及之后的实验内容，还不清楚该实现在之后会不会产生什么问题。另外编程时感觉冗余较大，应该还有更简洁高效的改进方法。


# 练习二
*1.* 页目录项和页表中每个组成部分的含义和以及对ucore而言的潜在用处

页目录表项中包含页表的基址和一些标志位，页表项中包含页基址和一些标志位。标志位在mmu.h中有如下定义：

    #define PTE_P           0x001                   // Present
    #define PTE_W           0x002                   // Writeable
    #define PTE_U           0x004                   // User
    #define PTE_PWT         0x008                   // Write-Through
    #define PTE_PCD         0x010                   // Cache-Disable
    #define PTE_A           0x020                   // Accessed
    #define PTE_D           0x040                   // Dirty
    #define PTE_PS          0x080                   // Page Size
    #define PTE_MBZ         0x180                   // Bits must be zero
    #define PTE_AVAIL       0xE00                   // Available for software use
    // The PTE_AVAIL bits aren't used by the kernel or interpreted by the
    // hardware, so user processes are allowed to set them arbitrarily. 
    
关于这些标志位，还是又一些不太明白的地方，查了80386的页目录表项和页表项，似乎UCore与其有所区别。简单来啦看，各个标志位的含义及对UCore的潜在用处如下：

PTE_P:页表或者页是否存在的标志位。该位用于判断相应的页表或者页是否存在，在进行地址映射时，需要对该位进行检查。这一标志位在多级页表中有用，可以减小页表的大小。每个进程不一定都要映射全物理内存空间，对于没有用到的内存空间，可动态第在相应的页表或者页目录表上将PTE_P置0，则该表项更下一级的页表不需要再存储，则可减少页表对内存的占用。

PTE_W:页表是否可写的权限控制位，可以用于权限控制和保护，这样是页式存储管理实现共享与保护机制所需。

PTE_U:判断该页是否是用户态，是否能被用户操作。

PTE_PWT:写穿透标志。该标志位在启用Cache有用，若该位为1，则每次写操作时，需要同时写Cache和主存。

PTE_PCD:是否启用Cache的标志。

PTE_A:访问标志,表示该页是刚加入内存尚未被访问，还是已经被访问过了。

PTE_D:表示该页是否是Dirty的。此标志位在虚拟内存中有用。当发生缺页时，需要从硬盘中把一个页调入内存，若此时内存没有空闲的页，则需要根据相应的替换算法替换一个页出去。Dirty表示该页是否被写过，若被写过，则替换时需要将其内容更新到硬盘（交换分区）中；若未被写过，则直接丢弃即可。

PTE_PS: 页的大小，可以根据offset来加以检查，看页内访问是否越界。

*2.* 如果ucore执行过程中访问内存，出现了页访问异常，请问硬件要做哪些事情

如果是与访问权限相关的异常，则操作系统会进入中断服务例程，进行报错等相关处理。如果是在使用了虚拟存储时，可能发生页缺失异常。此时是页表中的中对应的页并未在内存中。则此时，则需要取硬盘上的虚拟内存文件或交换分区中寻找相应的页加入到内存中，若内存无空闲页，则需要按照一定的替换算法替换出相应的页，如果该页被修改过，还需要将该页写回交换分区或虚拟内存文件中。然后还要重新执行之前的访存指令。


# 练习三
*1.* 数据结构Page的每一项与页表中的页目录项和页表项的对应关系
按照个人理解，page数组中的每一项都是一个page结构体，而每个page结构体中保存了内存里一个page的相关信息。在pmm.c中有如下代码：

    npage = maxpa / PGSIZE; 
    pages = (struct Page *)ROUNDUP((void *)end, PGSIZE); 
    for (i = 0; i < npage; i ++) {
        SetPageReserved(pages + i); 
    }
    uintptr_t freemem = PADDR((uintptr_t)pages + sizeof(struct Page) * npage);

即从end开始的地址，按页大小边界取整后，作为存储pages数组的空间，而从freemem开始到KMEMSIZE的内存，为实际可用的空闲内存空间。这部分连续空间按页划分后，与pages数组中的Page结构体相对应。页大小为4K，如果是按照32为寻址空间，则32为虚地址中，第12为为页内偏移0ffset，中间10为为页表项index，高10位为页目录项index。每一个页目录项都对应一个页表，每个页表有1k个页，加上pte_index则对应到一个页表项。每一个页表项对应一个实际的页。在pmm.c的get_page函数中有如下代码：
 
    pte_t *ptep = get_pte(pgdir, la, 0);
    if (ptep_store != NULL) {
        *ptep_store = ptep;
    }
    if (ptep != NULL && *ptep & PTE_P) {
        return pa2page(*ptep);
    }
    
其中每个页表项可以直接对应到page数组中的一个Page结构体。在pmm.h中列出了pa2page的实现：

    static inline struct Page *
    pa2page(uintptr_t pa) {
    if (PPN(pa) >= npage) {
        panic("pa2page called with invalid pa");
    }
    return &pages[PPN(pa)];

即将该表项对应到相应的页号中，以页号作为Rank对应到page数组中的一项。    

*2.* 修改lab2使得虚拟地址与物理地址相等

lab2中，因为段机制采用的是对等映射，即虚地址等于线性地址，则要使得虚地址等于物理地址，只需要使得线性地址等于物理地址即可。在lab2中，由于X86物理地址从0开始，而GCC编译器编译出的虚拟地址从0xC0000000开始，所以满足如下关系：

    virt addr = linear addr = phy addr + 0xC0000000
    
在pmm.h中的KADDR宏与PADDR宏完成物理地址到虚拟地址的映射，其中通过相应地址加减KERNBASE即0xC0000000，只需在此对该值进行修改即可。

# challenge——Buddy System

做了第一个扩展，在lab2的UCore实现了buddy分配算法，详细实现即测试代码在lab2->kern->mm中的buddy_pmm.c中，另外，为实现buddy system，对pmm.c和default_pmm.h也做了一定的修改。设计思路（可看做简要的设计文档）即测试说明如下：

*1.* 设计思路

# (1) # buddy分配的管理结构及存储

在实现上，借鉴了实验指导书中提供的关于buddy system一个极简实现的博文。博文中采用了一个结构体来存储相应的信息，结构体中包含一个变量记录总空间大小，以及一个数组来记录二叉树的信息。我直接在default_pmm.c中定义了一个unsigned数组指针buddy，然后用该数组存储二叉树的相应信息。总空间大小在buddy_pmm.c中用一个全局变量进行存储。参照那篇博文，用该unsigned数组是存储一个二叉树。二叉树的每个节点对应不断二分的空间信息，即每个数组元素存储的是该节点对应的内存块的大小。buddy system要求总空间以及每个块的大小都是2的整数次幂，根据前面的实验结果，能看到实际可利用的空间大小为32324页，所以在实现buddy system时，只取了其中的16384页(2^14)。而根据二叉树节点数目的关系，用于存储二叉树的数组开为总空间的两倍。在原来的lab2代码中，我们可以看到有如下代码：

    pages = (struct Page *)ROUNDUP((void *)end, PGSIZE); 
     for (i = 0; i < npage; i ++) {
        SetPageReserved(pages + i);  //将用来存内存管理结构pages的空间设为已用
    }
    uintptr_t freemem = PADDR((uintptr_t)pages + sizeof(struct Page) * npage);
    
即从Ucore结束后的地址开始，先存储用来管理的Page结构体，再从freemem开始是实际使用的空间。加入buddy system后，需要存储二叉树。于是从原来的pages结束处开始，存储buddy数组，再从buddy数组结束的地方开始算实际可用的内存空间，如下：

    pages = (struct Page *)ROUNDUP((void *)end, PGSIZE); 
     for (i = 0; i < npage; i ++) {
        SetPageReserved(pages + i);  //将用来存内存管理结构pages的空间设为已用
    }
    buddy = (unsigned *)ROUNDUP((void *)((uintptr_t)pages + sizeof(struct Page) * npage), PGSIZE);
    uintptr_t freemem= PADDR((uintptr_t)buddy + sizeof(unsigned) * npage*2);
    
# (1) # 初始化buddy_init_memmap

初始化时，和实现first-fit时类似，都需要对相关的page进行flags清零，标志位的设置等等。区别在于，在buddy system的实现中，不在需要原来的空闲块链表，此外，需要对buddy数组进行初始化：

    for (i = 1; i < len; i++) {
        int i1 = i+1;
        if (IS_POWER_OF_2(i1)) {
        	   size /= 2;
        }
        buddy[i] = size;
    }
    
即将二叉树按照从上到下，从左到右的顺序，把节点所对应的块大小依次填入buddy数组中。此时还需要主要，之后的alloc函数分配空间后，返回的是块的首个Page的指针，为了保持接口不变，分配释放的函数参数即返回值都不应该修改。原来分配时，是直接通过空闲块链表来获取相应的Page并返回。buddy system中，为了能在alloc获取对应的Page，在buddy_pmm.c中定义了一个全局Page结构体指针pagebase，并在buddy_init_memmap函数中，将空间空间的起始地址base存在pagebase里，之后分配时，只需要算出pagebase的rank即可获取。

# (2) # 分配buddy_alloc_pages

buddy system要求分配的空间必须为2的整数次幂，首先要检查要求分配的大小是否是2的整数次幂，不是的话，要向上舍入到最近的2的整数幂大小，如要求分配3，则应分配4的大小。在buddy_pmm.c中，定义了取左子节点index，右子节点index，父节点index，判断是否是2的幂次，向上舍入到2的幂次等函数和宏。确定了大小之后，则从二叉树的根节点进行搜索，找到满足要求的块并分配，搜索代码如下：

    for(node_size =  TOTAL_PAGE_NUM; node_size != n; node_size /= 2 ) {
    	   if (buddy[LEFT_LEAF(index)]  >= n) {
    	       index = LEFT_LEAF(index);
    	   }	else {
    	      index = RIGHT_LEAF(index);
    	   }
    }
    
这实际上是一个深度有限搜索，如此则可确保分配时，是按照地址从低到高，找到第一个满足要求的块，获取其index（在buddy数组中的位置），计算出是第几个page，然后返回pagebase中的相应元素即可。找到相应的块后，还需要对父节点的大小进行更新，更新代码如下：

    while (index) {
    	   index = PARENT(index);
       buddy[index] = MAX(buddy[LEFT_LEAF(index)], buddy[RIGHT_LEAF(index)]);
    }

另外需要说明的是，在之后的free函数中，由于接口保持不变，传入参数的仅仅是Page结构体和相应的大小，在buddy system的free中，需要确定该块在二叉树中节点的位置index，即buddy数组中的位置。在alloc时，通过jidex可以计算出块的首page在pagebase数组中的rank，反之，只要有该rank，也可计算出index。因此对Page结构体略作修改，在其中增加了一个unsigned类型的遍历offset，用于保存该块首Page在pagebase数组中的位置。

# (3) # 释放buddy_free_pages

释放时，传入Page结构体和相应大小，由于buddy system的实现，这里要求块大小和传入的参数大小应该一致，即不能传入一个4大小的块却只释放3个page。根据传入page中的offset变量值，计算出该节点在buddy数组中的index，将该数组值再次回复，然后从该节点向上再次逐一更新父节点接口。这里的实现与那篇博文中的略有区别，那篇博文是从叶子节点向上更新，然后遇到分配出去的节点就重置，退出循环。感觉这样的实现是有bug的，就没按照那个，而是直接定位到需要释放的节点。

# (4) # 测试buddy_check

重新写了此时函数，主要测试了buddy system的几个特性是否满足：若要求分配的块大小不是2的幂，则应向上舍入到临近的2的幂次；释放后，若相邻的两个空闲块大小和为2的幂次，则合并，大小和不为2的幂次则不和并；分配时，分配的块应该从低地址到高地址，按满足要去的大小分配等。具体测试代码详见buddy_pmm.c中的buddy_check函数。

#其他

*1.* 我的实现与lab2_result中的实现区别

first-fit算法的实现与lab2_result中有区别，具体见上述练习1中的描述。练习2与练习3，我的实现与lab2_result没有根本性的区别

*2.* 相关知识点

练习一涉及到了第五讲连续内存分配，使用到了里面关于first-fit算法的相关知识。当然，附录中课上没有讲到的知识点如物理内存分布与大小探测也对理解相关代码和流程有一定作用。

练习二涉及到的是非连续内存分配中的页式存储管理/多级页表等知识，尤其是线性地址在各级页表间的转换关系。

联系三涉及到的也是页式存储管理的相关知识，以及TLB相关的一些概念。




 


